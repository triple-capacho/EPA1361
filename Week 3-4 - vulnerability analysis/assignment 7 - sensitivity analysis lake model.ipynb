{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lake model continued\n",
    "\n",
    "In the previous week you used the lake problem as a means of getting aquinted with the workbench. In this assignment we will continue with the lake problem, focussing explicitly on using it for open exploration. You can use the second part of [this tutoria](https://emaworkbench.readthedocs.io/en/latest/indepth_tutorial/open-exploration.html) for help.\n",
    "\n",
    "**It is paramount that you are using the lake problem with 100 decision variables, rather than the one found on the website with the seperate anthropogenic release decision**\n",
    "\n",
    "## Apply sensitivity analysis\n",
    "There is substantial support in the ema_workbench for global sensitivity. For this, the workbench relies on [SALib](https://salib.readthedocs.io/en/latest/) and feature scoring which is a machine learning alternative for global sensitivity analysis. \n",
    "\n",
    "\n",
    "1. Apply Sobol with 3 seperate release policies (0, 0.05, and 0.1) and analyse the results for each release policy seperately focusing on the reliability objective. Do the sensitivities change depending on the release policy? Can you explain why or why not?\n",
    "\n",
    "*hint: you can use sobol sampling for the uncertainties, and set policies to a list with the 3 different release policies. Next, for the analysis using logical indexing on the experiment.policy column you can select the results for each seperate release policy and apply sobol to each of the three seperate release policies. If this sounds too complicated, just do it on each release policy seperately.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lakemodel_function import lake_problem as lake_model\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome, ScalarOutcome, Policy\n",
    "\n",
    "model = Model('LAKEMODEL', function=lake_model)\n",
    "\n",
    "model.uncertainties = [RealParameter('b', 0.1, 0.45),\n",
    "                       RealParameter('mean', 0.01, 0.05),\n",
    "                       RealParameter('q', 2, 4.5),\n",
    "                       RealParameter(\"stdev\", 0.001, 0.005),\n",
    "                       RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "model.levers = [RealParameter(f'l{i}', 0,0.1) for i in range(100)]\n",
    "\n",
    "\n",
    "model.outcomes = [ScalarOutcome('max_P'),\n",
    "                  ScalarOutcome('utility'),\n",
    "                  ScalarOutcome('inertia'),\n",
    "                  ScalarOutcome('reliability')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] performing 600 scenarios * 3 policies * 1 model(s) = 1800 experiments\n[MainProcess/INFO] performing experiments sequentially\n[MainProcess/INFO] 180 cases completed\n[MainProcess/INFO] 360 cases completed\n[MainProcess/INFO] 540 cases completed\n[MainProcess/INFO] 720 cases completed\n[MainProcess/INFO] 900 cases completed\n[MainProcess/INFO] 1080 cases completed\n[MainProcess/INFO] 1260 cases completed\n[MainProcess/INFO] 1440 cases completed\n[MainProcess/INFO] 1620 cases completed\n[MainProcess/INFO] 1800 cases completed\n[MainProcess/INFO] experiments finished\n"
    }
   ],
   "source": [
    "from SALib.analyze import sobol\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from ema_workbench import (MultiprocessingEvaluator, SequentialEvaluator ,ema_logging,\n",
    "                           perform_experiments)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with SequentialEvaluator(model) as evaluator:\n",
    "    sa_results = evaluator.perform_experiments(scenarios = 50 ,\n",
    "                                               uncertainty_sampling='sobol', policies=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = sa_results\n",
    "\n",
    "problem_1 = get_SALib_problem(model.uncertainties)\n",
    "Si_1 = sobol.analyze(problem_1, outcomes['max_P'],\n",
    "                   calc_second_order=True, print_to_console=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'problem' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-140fa7b5a726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mSi_filter_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mSi_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ST'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ST_conf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S1_conf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSi_df_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSi_filter_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSi_df_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'problem' is not defined"
     ]
    }
   ],
   "source": [
    "Si_filter_1 = {k:Si_1[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "Si_df_1 = pd.DataFrame(Si_filter_1, index = problem_1['names'])\n",
    "Si_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Repeat the above analysis for the 3 release policies but now with extra trees feature scoring and for all outcomes of interest. As a bonus, use the sobol experiment results as input for extra trees, and compare the results with those resulting from latin hypercube sampling.\n",
    "\n",
    "*hint: you can use [seaborn heatmaps](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for a nice figure of the results*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "b     delta      mean         q     stdev        l0        l1  \\\n0     0.176904  0.935801  0.030742  3.691895  0.002121  0.051048  0.008422   \n1     0.417529  0.935801  0.030742  3.691895  0.002121  0.051048  0.008422   \n2     0.176904  0.932754  0.030742  3.691895  0.002121  0.051048  0.008422   \n3     0.176904  0.935801  0.045977  3.691895  0.002121  0.051048  0.008422   \n4     0.176904  0.935801  0.030742  3.252441  0.002121  0.051048  0.008422   \n...        ...       ...       ...       ...       ...       ...       ...   \n1795  0.428296  0.976963  0.019746  3.820068  0.002311  0.079333  0.073568   \n1796  0.428296  0.946377  0.029160  3.820068  0.002311  0.079333  0.073568   \n1797  0.428296  0.946377  0.019746  2.357666  0.002311  0.079333  0.073568   \n1798  0.428296  0.946377  0.019746  3.820068  0.004354  0.079333  0.073568   \n1799  0.428296  0.946377  0.019746  3.820068  0.002311  0.079333  0.073568   \n\n           l10       l11       l12  ...       l93       l94       l95  \\\n0     0.060422  0.014711  0.018457  ...  0.004309  0.083458  0.079517   \n1     0.060422  0.014711  0.018457  ...  0.004309  0.083458  0.079517   \n2     0.060422  0.014711  0.018457  ...  0.004309  0.083458  0.079517   \n3     0.060422  0.014711  0.018457  ...  0.004309  0.083458  0.079517   \n4     0.060422  0.014711  0.018457  ...  0.004309  0.083458  0.079517   \n...        ...       ...       ...  ...       ...       ...       ...   \n1795  0.032560  0.066916  0.074502  ...  0.064034  0.018446  0.017289   \n1796  0.032560  0.066916  0.074502  ...  0.064034  0.018446  0.017289   \n1797  0.032560  0.066916  0.074502  ...  0.064034  0.018446  0.017289   \n1798  0.032560  0.066916  0.074502  ...  0.064034  0.018446  0.017289   \n1799  0.032560  0.066916  0.074502  ...  0.064034  0.018446  0.017289   \n\n           l96       l97       l98       l99  scenario  policy      model  \n0     0.015503  0.059811  0.078504  0.073232       600       3  LAKEMODEL  \n1     0.015503  0.059811  0.078504  0.073232       601       3  LAKEMODEL  \n2     0.015503  0.059811  0.078504  0.073232       602       3  LAKEMODEL  \n3     0.015503  0.059811  0.078504  0.073232       603       3  LAKEMODEL  \n4     0.015503  0.059811  0.078504  0.073232       604       3  LAKEMODEL  \n...        ...       ...       ...       ...       ...     ...        ...  \n1795  0.039815  0.068070  0.011467  0.058567      1195       5  LAKEMODEL  \n1796  0.039815  0.068070  0.011467  0.058567      1196       5  LAKEMODEL  \n1797  0.039815  0.068070  0.011467  0.058567      1197       5  LAKEMODEL  \n1798  0.039815  0.068070  0.011467  0.058567      1198       5  LAKEMODEL  \n1799  0.039815  0.068070  0.011467  0.058567      1199       5  LAKEMODEL  \n\n[1800 rows x 108 columns]\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}