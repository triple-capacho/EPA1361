{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lake model\n",
    "\n",
    "see also [this general introduction to the workbench](https://waterprogramming.wordpress.com/2017/11/01/using-the-exploratory-modelling-workbench/) as a source of inspiration for completing the assignment below\n",
    "\n",
    "## the lake model\n",
    "The exploratory modeling workbench includes an example folder. This folder contains a variety of examples that demonstrate the functionality of the workbench. Many of these examples have been drawn from published cases. Here, we use the Lake Problem as an example for demonstrating some of the key functionality of the workbench. \n",
    "\n",
    "We demonstrate some of the key capabilities of the exploratory modeling workbench using the Lake problem. The lake problem is a stylized and hypothetical decision problem where the population of a city has to decide on the amount of annual pollution it will put into a lake. It the pollution in the lake passes a threshold, it will suffer irreversible eutrophication. \n",
    "\n",
    "\\begin{equation}\n",
    "    X_{(t+1)}=X_t+a_t+\\frac{(X_t^q)}{(1+X_t^q )}- bX_t+\\epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "where $X_t$ is the pollution at time $t$, $a_t$ is the rate of anthropogenic pollution at time $t$, $b$ is the lake’s natural removal rate, $q$ is the lake's natural recycling rate, $\\epsilon_t$ is the rate of natural pollution at time $t$. The rate of anthropogenic pollution $a_t$ is the decision variable and is somewhere between 0, and 0.1. So $a_t \\in [0,0.1]$. The natural pollution $\\epsilon_t$ is modeled, following Singh et al. (2015), as a log normal distribution with mean $\\mu$ and standard deviation $\\sigma$. \n",
    "There are four outcomes of interest. The first is the average concentration of phosphor in the lake. \n",
    "\n",
    "\\begin{equation}\n",
    "    f_{phosphorus}=  \\frac{1}{\\left\\vert{T}\\right\\vert} \\sum\\limits_{t\\in{T}} X_t \n",
    "\\end{equation}\n",
    "\n",
    "where $\\left\\vert{T}\\right\\vert$ is the cardinality of the set of points in time. \n",
    "The second objective is the economic benefit derived from polluting the lake. Following Singh et al. (2015), this is defined as the discounted benefit of pollution mines the costs of having a polluted lake\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{economic} = \\sum\\limits_{t \\in {T}}\\alpha a_t \\delta^t \n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is the utility derived from polluting and $\\delta$ is the discount rate. By default, $\\alpha$ is 0.04.\n",
    "The third objective is related to the year over year change in the anthropogenic pollution rate. \n",
    "\n",
    "\\begin{equation}\n",
    "    f_{inertia} =\\frac{1}{\\left\\vert{T}\\right\\vert-1} \\sum\\limits_{t=1}^{\\left\\vert{T}\\right\\vert} I(|a_{t}-a_{t-1} |>\\tau)   \n",
    "\\end{equation}\n",
    "\n",
    "where $I$ is an indicator function that is 0 if the statement is false, and 1 if the statement is true, $\\tau$ is the threshold that is deemed undesirable, and is for illustrative purposes et to 0.2. Effectively, f_{inertia} is the fraction of years where the absolute value of the change in anthropogenic pollution is larger then $\\tau$.\n",
    "The fourth objective is the fraction of years where the pollution in the lake is below the critical threshold.\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{reliability} =  \\frac{1}{\\left\\vert{T}\\right\\vert} \\sum\\limits_{t \\in T}I(X_{t}<X_{crit} ) \n",
    "\\end{equation}\n",
    "\n",
    "where $I$ is an indicator function that is 0 if the statement is false, and 1 if the statement is true, $X_{crit}$ is the critical threshold of pollution and is a function of both $b$ and $q$.\n",
    "\n",
    "The lake problem is characterized by both stochastic uncertainty and deep uncertainty. The stochastic uncertainty arises from the natural inflow. To reduce this stochastic uncertainty, multiple replications are performed and the average over the replication is taken. Deep uncertainty is presented by uncertainty about the mean $\\mu$ and standard deviation $sigma$ of the lognormal distribution characterizing the natural inflow, the natural removal rate of the lake $\\beta$, the natural recycling rate of the lake $q$, and the discount rate $\\delta$. The table below specifies the ranges for the deeply uncertain factors, as well as their best estimate or default values. \n",
    "\n",
    "\n",
    "## Assignment\n",
    "1. Given the Python implementation of the lake problem in lakemodel_function.py, adapt this code and connect it to the workbench\n",
    "\n",
    "for the uncertainties, use the following table\n",
    "\n",
    "|Parameter\t|Range\t        |Default value|\n",
    "|-----------|--------------:|------------:|\n",
    "|$\\mu$    \t|0.01 – 0.05\t|0.02         |\n",
    "|$\\sigma$\t|0.001 – 0.005 \t|0.0017       |\n",
    "|$b$      \t|0.1 – 0.45\t    |0.42         |\n",
    "|$q$\t    |2 – 4.5\t    |2            |\n",
    "|$\\delta$\t|0.93 – 0.99\t|0.98         |\n",
    "\n",
    "For now, assume that for each year a release decision is made. The release is between 0 and 0.1. Carefully look at line 23 in lake_model.py to identify the name to use for each lever.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lakemodel_function import lake_problem as lake_model\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome, ScalarOutcome\n",
    "\n",
    "model = Model('LAKEMODEL', function=lake_model)\n",
    "\n",
    "model.uncertainties = [RealParameter('b', 0.1, 0.45),\n",
    "                       RealParameter('mean', 0.01, 0.05),\n",
    "                       RealParameter('q', 2, 4.5),\n",
    "                       RealParameter(\"stdev\", 0.001, 0.005),\n",
    "                       RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "model.levers = [RealParameter('l0', 0, 2),\n",
    "                RealParameter('l1', 0, 2),\n",
    "                RealParameter('l2', 0, 2),\n",
    "                RealParameter('l3', 0, 2)\n",
    "]\n",
    "\n",
    "model.outcomes = [ScalarOutcome('max_P'),\n",
    "                  ScalarOutcome('utility'),\n",
    "                  ScalarOutcome('inertia'),\n",
    "                  ScalarOutcome('reliability')]\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore the behavior of the system in the absence of any release using 1000 scenarios, and the default sampling approach.\n",
    "    * visualize the outcomes of interest, are there any apparent trade-offs?\n",
    "    * can you visually identify the uncertainties that drive system behavior?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] performing 100 scenarios * 4 policies * 1 model(s) = 400 experiments\n[MainProcess/INFO] performing experiments sequentially\n[MainProcess/INFO] 40 cases completed\n[MainProcess/INFO] 80 cases completed\n[MainProcess/INFO] 120 cases completed\n[MainProcess/INFO] 160 cases completed\n[MainProcess/INFO] 200 cases completed\n[MainProcess/INFO] 240 cases completed\n[MainProcess/INFO] 280 cases completed\n[MainProcess/INFO] 320 cases completed\n[MainProcess/INFO] 360 cases completed\n[MainProcess/INFO] 400 cases completed\n[MainProcess/INFO] experiments finished\nDone\n"
    }
   ],
   "source": [
    "from ema_workbench import SequentialEvaluator, ema_logging\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with SequentialEvaluator(model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios=100, policies=4)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explore the behavior of the system over 1000 scenarios for 4 randomly sampled candidate strategies.\n",
    "    * visualize the outcomes of interest\n",
    "    * what can you say about how the release decision influences the system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(400, 29)\n['max_P', 'utility', 'inertia', 'reliability']\nset policy\nchanged policy\ncreated df\nadded policy to df\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Selected KDE bandwidth is 0. Cannot estimate density.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\statsmodels\\nonparametric\\kde.py\u001b[0m in \u001b[0;36mkdensityfft\u001b[1;34m(X, kernel, bw, weights, gridsize, adjust, clip, cut, retgrid)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[0mbw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'scott'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e3f73d3223fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"added policy to df\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'policy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"created plot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36mpairplot\u001b[1;34m(data, hue, hue_order, palette, vars, x_vars, y_vars, kind, diag_kind, markers, height, aspect, corner, dropna, plot_kws, diag_kws, grid_kws, size)\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[0mdiag_kws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shade\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2120\u001b[0m             \u001b[0mdiag_kws\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"legend\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2121\u001b[1;33m             \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_diag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdiag_kws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2123\u001b[0m     \u001b[1;31m# Maybe plot on the off-diagonals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\seaborn\\axisgrid.py\u001b[0m in \u001b[0;36mmap_diag\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m   1488\u001b[0m                     \u001b[0mdata_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_na\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1490\u001b[1;33m                 \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clean_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[1;34m(data, data2, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade_lowest, cbar, cbar_ax, cbar_kws, ax, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m                                 cbar, cbar_ax, cbar_kws, ax, **kwargs)\n\u001b[0;32m    702\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         ax = _univariate_kdeplot(data, shade, vertical, kernel, bw,\n\u001b[0m\u001b[0;32m    704\u001b[0m                                  \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                                  cumulative=cumulative, **kwargs)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m_univariate_kdeplot\u001b[1;34m(data, shade, vertical, kernel, bw, gridsize, cut, clip, legend, ax, cumulative, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_has_statsmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;31m# Prefer using statsmodels for kernel flexibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         x, y = _statsmodels_univariate_kde(data, kernel, bw,\n\u001b[0m\u001b[0;32m    294\u001b[0m                                            \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                                            cumulative=cumulative)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m_statsmodels_univariate_kde\u001b[1;34m(data, kernel, bw, gridsize, cut, clip, cumulative)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[0mfft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gau\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[0mkde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKDEUnivariate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m     \u001b[0mkde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcumulative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[0mgrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\statsmodels\\nonparametric\\kde.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, kernel, bw, fft, weights, gridsize, adjust, cut, clip)\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Weights are not implemented for fft\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             density, grid, bw = kdensityfft(endog, kernel=kernel, bw=bw,\n\u001b[0m\u001b[0;32m    139\u001b[0m                     \u001b[0madjust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madjust\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                     clip=clip, cut=cut)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\statsmodels\\nonparametric\\kde.py\u001b[0m in \u001b[0;36mkdensityfft\u001b[1;34m(X, kernel, bw, weights, gridsize, adjust, clip, cut, retgrid)\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mbw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[0mbw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbandwidths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_bandwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkern\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# will cross-val fit this pattern?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m     \u001b[0mbw\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0madjust\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\statsmodels\\nonparametric\\bandwidths.py\u001b[0m in \u001b[0;36mselect_bandwidth\u001b[1;34m(x, bw, kernel)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;31m# eventually this can fall back on another selection criterion.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Selected KDE bandwidth is 0. Cannot estimate density.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Selected KDE bandwidth is 0. Cannot estimate density."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # TO DO; plot the scalers.\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "print(experiments.shape)\n",
    "print(list(outcomes.keys()))\n",
    "\n",
    "policies = experiments['policy']\n",
    "print(\"set policy\")\n",
    "for i, policy in enumerate(np.unique(policies)):\n",
    "    experiments.loc[policies==policy, 'policy'] = str(i)\n",
    "print(\"changed policy\")\n",
    "\n",
    "data = pd.DataFrame(outcomes)\n",
    "print(\"created df\")\n",
    "data['policy'] = policies\n",
    "print(\"added policy to df\")\n",
    "\n",
    "sns.pairplot(data, vars=list(outcomes.keys()))\n",
    "print(\"created plot\")\n",
    "plt.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If you have not used parallelization in the foregoing, try to adapt your code to use parallelization. The workbench comes with two evaluators for parallelization. The `MultiProcessingingEvaluator` and the `IpyparallelEvaluator`. When can you use each? Adapt your code from above and sue the `MultiProcessingingEvaluator`. Use the time library to check how much faster the computation for 1000 scenarios completes. \n",
    "\n",
    "Using multiprocessing within a jupyter notebook is tricky. On linux it will work in general just fine. On mac it depends on the version of Mac OS and the version of Python. If you are on the latest version of Mac OS in combination with Python 3.8, it might work but no guarantees. On older versions of Python it should work fine. On Windows it is always a problem. \n",
    "\n",
    "The underlying explanation is quite technical. It has to do with how your operating system creates the additional python processes. On windows, and the latest version of Mac OS in combination with Python 3.8. A completely new Python process is spawned. This new process does **not** inherit what is defined in memory of the parent process. The new child process will try to replicate what is in memory of the parent process by executing many of the import statements that have also been executed within the python process. Thus, if you define a model in the main process, it is not guaranteed to be known in the child processes. This is in particular true if you define the model within a jupyter notebook. Then the child processes will **never** know this function. Within jupyter notebooks, therefore, the best practice is to define your model within a .py file and import this .py file into the notebook. Now, each of the child processes will also execute this import statement and thus know the function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}