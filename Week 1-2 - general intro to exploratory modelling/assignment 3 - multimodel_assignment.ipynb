{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1361 - Model-Based Decision Making\n",
    "\n",
    "## Multi-model analysis\n",
    "\n",
    "This exercise uses a simple version of the [Lotka-Volterra predator-prey equations](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations) to show how the EMA Workbench can be used for a\n",
    "multi-model analysis, in addition to typical parametric/structural uncertainties. This will let you test the connectors provided in the Workbench for Excel, NetLogo, and Vensim / PySD; we'll also use the models for the sensitivity analysis exercise in week 3.\n",
    "\n",
    "* Using the three model files provided and the Python function below, define model objects for each implementation (Excel, NetLogo, Vensim/PySD, and Python), and test them using a single ensemble. Use 50 experiments sampled from the parameters below (so that each experiment will be executed for the 4 models, for a total of 200), and retrieve outputs for the _TIME_, _predators_, and _prey_ variables.\n",
    "    * excel and vensim are only supported on windows\n",
    "    * vensim requires 32 bit python, and a 7.1!! version of vensim DSS\n",
    "    * Netlogo supoprt depends on [jpype](http://jpype.readthedocs.io/en/latest/install.html) and [pynetlogo](https://pynetlogo.readthedocs.io/en/latest/). Also, if you don't have NetLogo installed, please get it from [NetLogo 6.0](https://ccl.northwestern.edu/netlogo/download.shtml) \n",
    "    * for pysd, see [its documentation](http://pysd.readthedocs.io/en/master/installation.html)\n",
    "    * If possible try to work with all model versions, but even 2 or 3 (pure python and something else should be sufficient).\n",
    "    \n",
    "\n",
    "|Parameter\t|Range or value\t        |\n",
    "|-----------|--------------:|\n",
    "|prey_birth_rate    \t|0.015 – 0.035\t|\n",
    "|predation_rate|0.0005 – 0.003 \t|\n",
    "|predator_efficiency     \t|0.001 – 0.004\t    |\n",
    "|predator_loss_rate\t    |0.04 – 0.08\t    |\n",
    "|Final time\t    |365\t    |\n",
    "|dt\t    |0.25\t    |\n",
    "\n",
    "* Note that your EMA Workbench installation includes example scripts for the different connectors. The different model objects follow a similar syntax but will need to be slightly adjusted depending on the software (e.g. to specify the NetLogo run length or the sheet name in Excel). \n",
    "\n",
    "* These model objects can be used with a replication functionality (for instance to test the effect of stochastic uncertainty in a NetLogo model), which repeats a given experiment over multiple replications. You can use a single replication in this exercise as the models are not stochastic. By default, each outcome array will then have a shape of (# experiments, # replications, # time steps). Try adapting the outcome arrays so that they can be used with the _lines_ plotting function of the Workbench, and plot the results grouped by model.\n",
    "\n",
    "* To check the graphical results, find the maximum absolute error of the time series you obtained for the _prey_ variable in the Excel, NetLogo, and Vensim/PySD models, relative to the Python function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Users\\supriya.kr09\\anaconda33\\lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:48: ImportWarning: platypus based optimization not available\n  warnings.warn(\"platypus based optimization not available\", ImportWarning)\nC:\\Users\\supriya.kr09\\anaconda33\\lib\\site-packages\\ema_workbench\\connectors\\__init__.py:17: ImportWarning: vensim connector not available\n  warnings.warn(\"vensim connector not available\", ImportWarning)\nC:\\Users\\supriya.kr09\\anaconda33\\lib\\site-packages\\ema_workbench\\analysis\\prim.py:31: ImportWarning: altair based interactive inspection not available\n  \"inspection not available\"), ImportWarning)\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, perform_experiments,\n",
    "                           ema_logging, Constant)\n",
    "\n",
    "from ema_workbench.connectors.netlogo import NetLogoModel\n",
    "from ema_workbench.connectors.excel import ExcelModel\n",
    "from ema_workbench.connectors.pysd_connector import PysdModel\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import LHS, SOBOL, MORRIS\n",
    "\n",
    "from ema_workbench.analysis.plotting import lines, Density\n",
    "\n",
    "\n",
    "def PredPrey(prey_birth_rate=0.025, predation_rate=0.0015, predator_efficiency=0.002,\n",
    "             predator_loss_rate=0.06, initial_prey=50, initial_predators=20, dt=0.25, final_time=365, reps=1):\n",
    "\n",
    "    #Initial values\n",
    "    predators, prey, sim_time = [np.zeros((reps, int(final_time/dt)+1)) for _ in range(3)]\n",
    "    \n",
    "    for r in range(reps):\n",
    "        predators[r,0] = initial_predators\n",
    "        prey[r,0] = initial_prey\n",
    "\n",
    "        #Calculate the time series\n",
    "        for t in range(0, sim_time.shape[1]-1):\n",
    "\n",
    "            dx = (prey_birth_rate*prey[r,t]) - (predation_rate*prey[r,t]*predators[r,t])\n",
    "            dy = (predator_efficiency*predators[r,t]*prey[r,t]) - (predator_loss_rate*predators[r,t])\n",
    "\n",
    "            prey[r,t+1] = max(prey[r,t] + dx*dt, 0)\n",
    "            predators[r,t+1] = max(predators[r,t] + dy*dt, 0)\n",
    "            sim_time[r,t+1] = (t+1)*dt\n",
    "    \n",
    "    #Return outcomes\n",
    "    return {'TIME':sim_time,\n",
    "            'predators':predators,\n",
    "            'prey':prey}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'TIME': array([[0.0000e+00, 2.5000e-01, 5.0000e-01, ..., 3.6450e+02, 3.6475e+02,\n        3.6500e+02]]), 'predators': array([[20.        , 20.2       , 20.40136875, ..., 37.69187459,\n        37.72581658, 37.75505957]]), 'prey': array([[50.        , 49.9375    , 49.87133281, ..., 31.8010242 ,\n        31.55029052, 31.30113215]])}\n"
    }
   ],
   "source": [
    "## for testing\n",
    "\n",
    "print(PredPrey())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## excel\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from ema_workbench import (RealParameter, TimeSeriesOutcome, ema_logging,\n",
    "                           perform_experiments)\n",
    "\n",
    "from ema_workbench.connectors.excel import ExcelModel\n",
    "from ema_workbench.em_framework.evaluators import MultiprocessingEvaluator, SequentialEvaluator\n",
    "from ema_workbench.analysis import plotting, plotting_util\n",
    "\n",
    "ema_logging.log_to_stderr(level=ema_logging.INFO)\n",
    "\n",
    "excel_model = ExcelModel(\"predatorPrey\", wd='./model', model_file='./PredPrey.xlsx')\n",
    "\n",
    "excel_model.uncertainties = [RealParameter('prey_birth_rate', 0.015, 0.035),\n",
    "                       RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                       RealParameter('predator_efficiency', 0.001, 0.004),\n",
    "                       RealParameter(\"predator_loss_rate\", 0.04, 0.08)]\n",
    "\n",
    "excel_model.outcomes =  [TimeSeriesOutcome('predators'), TimeSeriesOutcome('prey')]\n",
    "# name of the sheet\n",
    "excel_model.default_sheet = \"Sheet1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] performing 50 scenarios * 1 policies * 1 model(s) = 50 experiments\n[MainProcess/INFO] performing experiments sequentially\n[MainProcess/INFO] 5 cases completed\n[MainProcess/INFO] 10 cases completed\n[MainProcess/INFO] 15 cases completed\n[MainProcess/INFO] 20 cases completed\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0ae888defa3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexcel_model\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexcel_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreporting_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mperform_experiments\u001b[1;34m(models, scenarios, policies, evaluator, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, levers_sampling, callback, return_callback)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m     \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscenarios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnr_of_exp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mevaluate_experiments\u001b[1;34m(self, scenarios, policies, callback)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mex_gen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0moutcomes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCaseError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;31m# object instance as first arguments in args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'calling {} on {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             logger.debug(\n\u001b[0;32m    160\u001b[0m                 'completed calling {} on {}'.format(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(self, scenario, policy)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mexperiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutcomes_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;31m# object instance as first arguments in args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'calling {} on {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             logger.debug(\n\u001b[0;32m    160\u001b[0m                 'completed calling {} on {}'.format(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\connectors\\excel.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;31m# set values on sheet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_wb_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# trigger a calulate event, in the case that the workbook's automatic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\connectors\\excel.py\u001b[0m in \u001b[0;36mset_wb_value\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[0msheet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mcom_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             _logger.warning(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\win32com\\client\\dynamic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, attr, value)\u001b[0m\n\u001b[0;32m    563\u001b[0m                                         \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_olerepr_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropMapPut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m                                         \u001b[0minvoke_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_GetDescInvokeType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpythoncom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINVOKE_PROPERTYPUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_oleobj_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvoke_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m                                         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Run experiment excel\n",
    "\n",
    "with SequentialEvaluator(excel_model) as evaluator:\n",
    "    results = perform_experiments(excel_model, 50, reporting_interval=5, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## netlogo \n",
    "\n",
    "import numpy as np\n",
    "import ctypes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from ema_workbench import (RealParameter, TimeSeriesOutcome, ema_logging,\n",
    "                           perform_experiments)\n",
    "\n",
    "from ema_workbench.connectors.netlogo import NetLogoModel\n",
    "from ema_workbench.em_framework.evaluators import MultiprocessingEvaluator, SequentialEvaluator\n",
    "from ema_workbench.analysis import plotting, plotting_util\n",
    "\n",
    "ema_logging.log_to_stderr(level=ema_logging.INFO)\n",
    "\n",
    "netlogo_model = NetLogoModel(\"predatorPrey\", wd='./model', model_file='./PredPrey.nlogo')\n",
    "netlogo_model.run_length = 365\n",
    "netlogo_model.replications = 1\n",
    "\n",
    "netlogo_model.uncertainties = [RealParameter('prey_birth_rate', 0.015, 0.035),\n",
    "                       RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                       RealParameter('predator_efficiency', 0.001, 0.004),\n",
    "                       RealParameter(\"predator_loss_rate\", 0.04, 0.08)]\n",
    "\n",
    "netlogo_model.outcomes =  [TimeSeriesOutcome('predators'), TimeSeriesOutcome('prey')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] performing 50 scenarios * 1 policies * 1 model(s) = 50 experiments\n[MainProcess/INFO] performing experiments sequentially\n[MainProcess/INFO] 1 cases completed\n[MainProcess/INFO] 2 cases completed\n[MainProcess/INFO] 3 cases completed\n[MainProcess/INFO] 4 cases completed\n[MainProcess/INFO] 5 cases completed\n[MainProcess/INFO] 6 cases completed\n[MainProcess/INFO] 7 cases completed\n[MainProcess/INFO] 8 cases completed\n[MainProcess/INFO] 9 cases completed\n[MainProcess/INFO] 10 cases completed\n[MainProcess/INFO] 11 cases completed\n[MainProcess/INFO] 12 cases completed\n[MainProcess/INFO] 13 cases completed\n[MainProcess/INFO] 14 cases completed\n[MainProcess/INFO] 15 cases completed\n[MainProcess/INFO] 16 cases completed\n[MainProcess/INFO] 17 cases completed\n[MainProcess/INFO] 18 cases completed\n[MainProcess/INFO] 19 cases completed\n[MainProcess/INFO] 20 cases completed\n[MainProcess/INFO] 21 cases completed\n[MainProcess/INFO] 22 cases completed\n[MainProcess/INFO] 23 cases completed\n[MainProcess/INFO] 24 cases completed\n[MainProcess/INFO] 25 cases completed\n[MainProcess/INFO] 26 cases completed\n[MainProcess/INFO] 27 cases completed\n[MainProcess/INFO] 28 cases completed\n[MainProcess/INFO] 29 cases completed\n[MainProcess/INFO] 30 cases completed\n[MainProcess/INFO] 31 cases completed\n[MainProcess/INFO] 32 cases completed\n[MainProcess/INFO] 33 cases completed\n[MainProcess/INFO] 34 cases completed\n[MainProcess/INFO] 35 cases completed\n[MainProcess/INFO] 36 cases completed\n[MainProcess/INFO] 37 cases completed\n[MainProcess/INFO] 38 cases completed\n[MainProcess/INFO] 39 cases completed\n[MainProcess/INFO] 40 cases completed\n[MainProcess/INFO] 41 cases completed\n[MainProcess/INFO] 42 cases completed\n[MainProcess/INFO] 43 cases completed\n[MainProcess/INFO] 44 cases completed\n[MainProcess/INFO] 45 cases completed\n[MainProcess/INFO] 46 cases completed\n[MainProcess/INFO] 47 cases completed\n[MainProcess/INFO] 48 cases completed\n[MainProcess/INFO] 49 cases completed\n[MainProcess/INFO] 50 cases completed\n[MainProcess/INFO] experiments finished\n"
    }
   ],
   "source": [
    "## run experiment netlogo\n",
    "\n",
    "with SequentialEvaluator(netlogo_model) as evaluator:\n",
    "    results = perform_experiments(netlogo_model, 50, reporting_interval=1, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pysd\n",
    "\n",
    "import numpy as np\n",
    "import ctypes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from ema_workbench import (RealParameter, TimeSeriesOutcome, ema_logging,\n",
    "                           perform_experiments)\n",
    "\n",
    "from ema_workbench.connectors.pysd_connector import PysdModel\n",
    "from ema_workbench.em_framework.evaluators import MultiprocessingEvaluator, SequentialEvaluator\n",
    "from ema_workbench.analysis import plotting, plotting_util\n",
    "\n",
    "ema_logging.log_to_stderr(level=ema_logging.INFO)\n",
    "\n",
    "pysd_model = PysdModel(\"predatorPrey\", mdl_file='./model/PredPrey.mdl')\n",
    "\n",
    "\n",
    "pysd_model.uncertainties = [RealParameter('prey_birth_rate', 0.015, 0.035),\n",
    "                       RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                       RealParameter('predator_efficiency', 0.001, 0.004),\n",
    "                       RealParameter(\"predator_loss_rate\", 0.04, 0.08)]\n",
    "\n",
    "pysd_model.outcomes =  [TimeSeriesOutcome('predators'), TimeSeriesOutcome('prey')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pysd_model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e8702e57d895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## run pysd experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpysd_model\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperform_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpysd_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreporting_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pysd_model' is not defined"
     ]
    }
   ],
   "source": [
    "## run pysd experiment\n",
    "\n",
    "with SequentialEvaluator(pysd_model) as evaluator:\n",
    "    results = perform_experiments(pysd_model, 50, reporting_interval=1, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  python model....\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome, ScalarOutcome\n",
    "\n",
    "py_model = Model('pypredprey', function=PredPrey)\n",
    "\n",
    "py_model.uncertainties = [RealParameter('prey_birth_rate', 0.015, 0.035),\n",
    "                       RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                       RealParameter('predator_efficiency', 0.001, 0.004),\n",
    "                       RealParameter(\"predator_loss_rate\", 0.04, 0.08)]\n",
    "\n",
    "# model.levers = [RealParameter('initial_prey', 25, 75),\n",
    "#                 RealParameter('initial_predators', 10,30)]\n",
    "\n",
    "py_model.constants = [Constant('final_time', 365),\n",
    "                    Constant('dt', 0.25)]\n",
    "\n",
    "py_model.outcomes =  [TimeSeriesOutcome('predators'), TimeSeriesOutcome('prey')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the experiments python\n",
    "from ema_workbench import (MultiprocessingEvaluator, SequentialEvaluator ,ema_logging,\n",
    "                           perform_experiments)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with SequentialEvaluator(py_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=50)\n",
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] performing 50 scenarios * 1 policies * 4 model(s) = 200 experiments\n[MainProcess/INFO] performing experiments sequentially\n[MainProcess/INFO] 5 cases completed\n[MainProcess/INFO] 10 cases completed\n[MainProcess/INFO] 15 cases completed\n[MainProcess/INFO] 20 cases completed\n[MainProcess/INFO] 25 cases completed\n[MainProcess/INFO] 30 cases completed\n[MainProcess/INFO] 35 cases completed\n[MainProcess/INFO] 40 cases completed\n[MainProcess/INFO] 45 cases completed\n[MainProcess/INFO] 50 cases completed\n[MainProcess/INFO] 55 cases completed\n[MainProcess/INFO] 60 cases completed\n[MainProcess/INFO] 65 cases completed\n[MainProcess/INFO] 70 cases completed\n[MainProcess/INFO] 75 cases completed\n[MainProcess/INFO] 80 cases completed\n[MainProcess/INFO] 85 cases completed\n[MainProcess/INFO] 90 cases completed\n[MainProcess/INFO] 95 cases completed\n[MainProcess/INFO] 100 cases completed\n[MainProcess/INFO] 105 cases completed\n[MainProcess/INFO] 110 cases completed\n[MainProcess/INFO] 115 cases completed\n[MainProcess/INFO] 120 cases completed\n[MainProcess/INFO] 125 cases completed\n[MainProcess/INFO] 130 cases completed\n[MainProcess/INFO] 135 cases completed\n[MainProcess/INFO] 140 cases completed\n[MainProcess/INFO] 145 cases completed\n[MainProcess/INFO] 150 cases completed\n[MainProcess/INFO] 155 cases completed\n[MainProcess/INFO] 160 cases completed\n[MainProcess/INFO] 165 cases completed\n[MainProcess/INFO] 170 cases completed\n[MainProcess/INFO] 175 cases completed\n[MainProcess/INFO] 180 cases completed\n[MainProcess/INFO] 185 cases completed\n[MainProcess/INFO] 190 cases completed\n[MainProcess/INFO] 195 cases completed\n[MainProcess/INFO] 200 cases completed\n[MainProcess/INFO] experiments finished\n"
    }
   ],
   "source": [
    "## run all experiments simultaneously, but not with multiprocessing\n",
    "\n",
    "from ema_workbench import (MultiprocessingEvaluator, SequentialEvaluator ,ema_logging,\n",
    "                           perform_experiments)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "models = [py_model, excel_model, netlogo_model, pysd_model]\n",
    "\n",
    "with SequentialEvaluator(models) as evaluator:\n",
    "    results = evaluator.perform_experiments(50, reporting_interval=5)\n",
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mulitprocessing multiple models\n",
    "\n",
    "# from ema_workbench import (MultiprocessingEvaluator, SequentialEvaluator ,ema_logging,\n",
    "#                            perform_experiments)\n",
    "# ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# models = [py_model, excel_model]\n",
    "\n",
    "# with MultiprocessingEvaluator(models) as mulEval:\n",
    "#     results = mulEval.perform_experiments(50, reporting_interval=5)\n",
    "# experiments_2, outcomes_2 = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(50, 7)\n['predators', 'prey']\n{'predators': array([[[20.        , 20.02864784, 20.05468535, ...,  2.10353838,\n          2.0900741 ,  2.07673144]],\n\n       [[20.        , 20.21612445, 20.43574092, ..., 21.54869453,\n         21.40077224, 21.25408688]],\n\n       [[20.        , 20.61840443, 21.24999425, ...,  1.04649058,\n          1.03747007,  1.02860463]],\n\n       ...,\n\n       [[20.        , 20.04345978, 20.08447236, ...,  2.36919127,\n          2.35707488,  2.34509182]],\n\n       [[20.        , 20.34114924, 20.68248664, ...,  1.22204159,\n          1.21037717,  1.19886522]],\n\n       [[20.        , 20.14315219, 20.28495979, ...,  4.39797485,\n          4.39249087,  4.38732262]]]), 'prey': array([[[50.        , 49.5028549 , 49.00961991, ..., 20.58256053,\n         20.64621432, 20.71026744]],\n\n       [[50.        , 50.12717654, 50.25190157, ..., 10.71721519,\n         10.74022336, 10.76368787]],\n\n       [[50.        , 49.71098527, 49.40248994, ..., 10.30546103,\n         10.38028245, 10.45571153]],\n\n       ...,\n\n       [[50.        , 49.63086889, 49.26318519, ..., 28.78734605,\n         28.87548346, 28.96409797]],\n\n       [[50.        , 49.6074519 , 49.20737169, ..., 12.27694409,\n         12.32514418, 12.37362367]],\n\n       [[50.        , 49.77746158, 49.55209878, ..., 34.09841123,\n         34.23146107, 34.36513056]]])}\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-98bc822fa887>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#print(\"created df\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'policy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m#print(\"added policy to df\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#print(data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # TO DO; plot the scalers.\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "experiments, outcomes = results\n",
    "\n",
    "print(experiments.shape)\n",
    "print(list(outcomes.keys()))\n",
    "print(outcomes)\n",
    "policies = experiments['policy']\n",
    "#print(policies)\n",
    "#print(\"set policy\")\n",
    "\n",
    "data = (pd.DataFrame([outcomes]), type == object)\n",
    "#df = pd.DataFrame.from_records([outcomes], index = [0])\n",
    "\n",
    "#pd.Series(data).to_frame()\n",
    "\n",
    "\n",
    "#print(\"created df\")\n",
    "data['policy'] = policies\n",
    "#print(\"added policy to df\")\n",
    "#print(data)\n",
    "\n",
    "sns.pairplot(data, hue='policy', vars=list(outcomes.keys()), diag_kind='hist')\n",
    "#print(\"created plot\")\n",
    "plt.show()\n",
    "#print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting which does not work\n",
    "\n",
    "# import matplotlib.pyplot as plt # TO DO; plot the scalers.\n",
    "# import pandas as pd\n",
    "# import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "#print(experiments.shape)\n",
    "#print(list(outcomes.keys()))\n",
    "\n",
    "# policies = experiments['policy']\n",
    "#print(policies)\n",
    "#print(\"set policy\")\n",
    "# for i, policy in enumerate(np.unique(policies)):\n",
    "#     experiments.loc[policies==policy, 'policy'] = str(i)\n",
    "#print(\"changed policy\")\n",
    "\n",
    "# print(outcomes['predators'])\n",
    "# for outcome in outcomes.keys():\n",
    "#     for x in range(0, len(outcomes[outcome])):\n",
    "#         for i in range(0, len(outcomes[outcome][x][0])):\n",
    "\n",
    "# print(outcomes['predators'])\n",
    "# data = pd.DataFrame(outcomes)\n",
    "# #print(\"created df\")\n",
    "# data['policy'] = policies\n",
    "#print(\"added policy to df\")\n",
    "# print(data)\n",
    "\n",
    "# sns.pairplot(data, vars=list(outcomes.keys()), diag_kind='auto')\n",
    "# #print(\"created plot\")\n",
    "# plt.show()\n",
    "#print(\"done\")\n",
    "# from ema_workbench.analysis import plotting, plotting_util\n",
    "\n",
    "# for outcome in outcomes.keys():\n",
    "#     print(outcome)\n",
    "#     plotting.lines(experiments, outcomes, outcomes_to_show=outcome, density=plotting_util.Density.HIST)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}