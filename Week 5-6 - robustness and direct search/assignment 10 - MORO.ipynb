{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-objective Robust Optimization (MORO)\n",
    "\n",
    "\n",
    "This exercise demostrates the application of MORO on the lake model. In contrast to the exercises in previous weeks, we will be using a slightly more sophisticated version of the problem. For details see the MORDM assignment for this week.\n",
    "\n",
    "## Setup MORO\n",
    "\n",
    "Many objective robust optimization aims at finding decisions that are robust with respect to the various deeply uncertain factors. For this, MORO evalues each candidate decision over a set of scenarios. For each outcome of interest, the robusntess over this set is calculated. A MOEA is used to maximize the robustness. \n",
    "\n",
    "For this assignment, we will be using a domain criterion as our robustness metric. The table below lists the rules that you should use for each outcome of interest.\n",
    "\n",
    "|Outcome of interest| threhsold  |\n",
    "|-------------------|------------|\n",
    "| Maximum pollution | $\\leq$ 0.75|\n",
    "| Inertia           | $\\geq$ 0.6 |\n",
    "| Reliability       | $\\geq$ 0.99|   \n",
    "| Utility           | $\\geq$ 0.75|\n",
    "\n",
    "**1) Implement a function for each outcome that takes a numpy array with results for the outcome of interest, and returns the robustness score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] pool started\n[MainProcess/INFO] generation 0: 0/1000 nfe\n[MainProcess/INFO] generation 5: 29/1000 nfe\n[MainProcess/INFO] generation 10: 58/1000 nfe\n[MainProcess/INFO] generation 15: 88/1000 nfe\n[MainProcess/INFO] generation 20: 118/1000 nfe\n[MainProcess/INFO] generation 25: 148/1000 nfe\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3f5bf75347ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mMultiprocessingEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlake_model\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     evaluator.robust_optimize(robustnes_functions, scenarios, nfe=nfe,\n\u001b[0m\u001b[0;32m     71\u001b[0m                                 \u001b[0mepsilons\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrobustnes_functions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                                 population_size=5)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mrobust_optimize\u001b[1;34m(self, robustness_functions, scenarios, algorithm, nfe, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         '''\n\u001b[1;32m--> 201\u001b[1;33m         return robust_optimize(self._msis, robustness_functions, scenarios,\n\u001b[0m\u001b[0;32m    202\u001b[0m                                \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnfe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnfe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                                \u001b[0mconvergence_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvergence_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mrobust_optimize\u001b[1;34m(model, robustness_functions, scenarios, evaluator, algorithm, nfe, convergence, constraints, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m     return _optimize(problem, evaluator, algorithm, convergence,\n\u001b[0m\u001b[0;32m    585\u001b[0m                      int(nfe), convergence_freq, logging_freq, **kwargs)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\optimization.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(problem, evaluator, algorithm, convergence, nfe, convergence_freq, logging_freq, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     with temporary_filter(name=[callbacks.__name__,\n\u001b[0;32m    828\u001b[0m                                 evaluators.__name__], level=INFO):\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnfe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m     results = to_dataframe(optimizer, problem.parameter_names,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\platypus\\core.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, condition, callback)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_frequency\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlast_log\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_frequency\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\platypus\\algorithms.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1522\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1523\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1524\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\platypus\\algorithms.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marchive\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\platypus\\algorithms.py\u001b[0m in \u001b[0;36miterate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0moffspring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0moffspring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\platypus\\core.py\u001b[0m in \u001b[0;36mevaluate_all\u001b[1;34m(self, solutions)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mjobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_EvaluateJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munevaluated\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# if needed, update the original solution with the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mevaluate_all\u001b[1;34m(self, jobs, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# overwrite the default 10 progress reports  with 5 reports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         callback = perform_experiments(\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_msis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mevaluator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mperform_experiments\u001b[1;34m(models, scenarios, policies, evaluator, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, levers_sampling, callback, return_callback)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m     \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscenarios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnr_of_exp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py\u001b[0m in \u001b[0;36mevaluate_experiments\u001b[1;34m(self, scenarios, policies, callback)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscenarios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mex_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscenarios\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_msis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0madd_tasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_processes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mex_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ema_workbench\\em_framework\\ema_multiprocessing.py\u001b[0m in \u001b[0;36madd_tasks\u001b[1;34m(n_processes, pool, experiments, callback)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[0mfeeder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[0mresults_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m     \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, ScalarOutcome, Constant,\n",
    "                           ema_logging, MultiprocessingEvaluator)\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "from dps_lake_model import lake_model as lake_problem\n",
    "\n",
    "# instantiate the model\n",
    "lake_model = Model('lakeproblem', function=lake_problem)\n",
    "# specify uncertainties\n",
    "lake_model.uncertainties = [RealParameter('b', 0.1, 0.45),\n",
    "                            RealParameter('q', 2.0, 4.5),\n",
    "                            RealParameter('mean', 0.01, 0.05),\n",
    "                            RealParameter('stdev', 0.001, 0.005),\n",
    "                            RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers\n",
    "lake_model.levers = [RealParameter(\"c1\", -2, 2),\n",
    "                        RealParameter(\"c2\", -2, 2),\n",
    "                        RealParameter(\"r1\", 0, 2),\n",
    "                        RealParameter(\"r2\", 0, 2),\n",
    "                        RealParameter(\"w1\", 0, 1)\n",
    "                        ]\n",
    "\n",
    "# specify outcomes\n",
    "lake_model.outcomes = [ScalarOutcome('max_P'),\n",
    "                        ScalarOutcome('utility'),\n",
    "                        ScalarOutcome('inertia'),\n",
    "                        ScalarOutcome('reliability')]\n",
    "\n",
    "# override some of the defaults of the model\n",
    "lake_model.constants = [Constant('alpha', 0.41),\n",
    "                        Constant('nsamples', 100),\n",
    "                        Constant('myears', 100)]\n",
    "\n",
    "# setup and execute the robust optimization\n",
    "def signal_to_noise(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    sn = mean / std\n",
    "    return sn\n",
    "\n",
    "MAXIMIZE = ScalarOutcome.MAXIMIZE  # @UndefinedVariable\n",
    "MINIMIZE = ScalarOutcome.MINIMIZE  # @UndefinedVariable\n",
    "robustnes_functions = [\n",
    "    ScalarOutcome(\n",
    "        'mean p',\n",
    "        kind=MINIMIZE,\n",
    "        variable_name='max_P',\n",
    "        function=np.mean),\n",
    "    ScalarOutcome(\n",
    "        'std p',\n",
    "        kind=MINIMIZE,\n",
    "        variable_name='max_P',\n",
    "        function=np.std),\n",
    "    ScalarOutcome(\n",
    "        'sn reliability',\n",
    "        kind=MAXIMIZE,\n",
    "        variable_name='reliability',\n",
    "        function=signal_to_noise)]\n",
    "n_scenarios = 10\n",
    "scenarios = sample_uncertainties(lake_model, n_scenarios)\n",
    "nfe = 1000\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    evaluator.robust_optimize(robustnes_functions, scenarios, nfe=nfe,\n",
    "                                epsilons=[0.1, ] * len(robustnes_functions),\n",
    "                                population_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (RealParameter, ScalarOutcome, Constant,\n",
    "                           Model)\n",
    "import functools\n",
    "\n",
    "def robustness(direction, threshold, data):\n",
    "    if direction == SMALLER:\n",
    "        return np.sum(data<=threshold)/data.shape[0]\n",
    "    else:\n",
    "        return np.sum(data>=threshold)/data.shape[0]\n",
    "\n",
    "def maxp(data):\n",
    "    return np.sum(data<=0.75)/data.shape[0]\n",
    "    \n",
    "SMALLER = 'SMALLER'\n",
    "LARGER = 'LARGER'\n",
    "\n",
    "maxp2 = functools.partial(robustness, SMALLER, 0.75)\n",
    "inertia = functools.partial(robustness, LARGER, 0.6)\n",
    "reliability = functools.partial(robustness, LARGER, 0.99)\n",
    "utility = functools.partial(robustness, LARGER, 0.75)\n",
    "\n",
    "MAXIMIZE = ScalarOutcome.MAXIMIZE\n",
    "MINIMIZE = ScalarOutcome.MINIMIZE\n",
    "# choose one, not sure which. \n",
    "# First is okay but not advised. \n",
    "# robustnes_functions = [ScalarOutcome('90th percentile max_p', kind=MINIMIZE,\n",
    "#                              variable_name='max_P', function=maxp),\n",
    "#                        ScalarOutcome('10th percentile reliability', kind=MAXIMIZE,\n",
    "#                              variable_name='reliability', function=reliability),\n",
    "#                        ScalarOutcome('10th percentile inertia', kind=MAXIMIZE,\n",
    "#                              variable_name='inertia', function=inertia),\n",
    "#                        ScalarOutcome('10th percentile utility', kind=MAXIMIZE,\n",
    "#                              variable_name='utility', function=utility)]\n",
    "\n",
    "robustnes_maxp_function = [ScalarOutcome('max_p', kind=MINIMIZE,\n",
    "                             variable_name='max_P', function=maxp)]\n",
    "robustnes_reliability_function = [ScalarOutcome('reliability', kind=MAXIMIZE,\n",
    "                             variable_name='reliability', function=reliability)]\n",
    "robustnes_inertia_function = [ScalarOutcome('inertia', kind=MAXIMIZE,\n",
    "                             variable_name='inertia', function=inertia)]\n",
    "robustnes_utility_function = [ScalarOutcome('utility', kind=MAXIMIZE,\n",
    "                             variable_name='utility', function=utility)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Generate 4 random release policies, and evaluate them over 500 scenarios. Sample the scenarios using Monte Carlo sampling. Next evaulate your robustness function for 1, 2, 3, ... 500 scenarios for each outcome and visualize this. What can you tell about the convergernce of the robusntess metric as a function of the number of scenarios?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (MultiprocessingEvaluator, ema_logging,\n",
    "                           perform_experiments)\n",
    "from ema_workbench.em_framework.evaluators import MC\n",
    "from dps_lake_model import lake_model as lakeModel\n",
    "lake_model = Model('lakeproblem', function=lakeModel)\n",
    "# instantiate model\n",
    "lake_model.uncertainties = [RealParameter('b', 0.1, 0.45),\n",
    "                                RealParameter('q', 2.0, 4.5),\n",
    "                                RealParameter('mean', 0.01, 0.05),\n",
    "                                RealParameter('stdev', 0.001, 0.005),\n",
    "                                RealParameter('delta', 0.93, 0.99)]\n",
    "\n",
    "# set levers\n",
    "lake_model.levers = [RealParameter(\"c1\", -2, 2),\n",
    "                         RealParameter(\"c2\", -2, 2),\n",
    "                         RealParameter(\"r1\", 0, 2),\n",
    "                         RealParameter(\"r2\", 0, 2),\n",
    "                         RealParameter(\"w1\", 0, 1)\n",
    "                         ]\n",
    "\n",
    "# specify outcomes\n",
    "lake_model.outcomes = [ScalarOutcome('max_P'),\n",
    "                           ScalarOutcome('utility'),\n",
    "                           ScalarOutcome('inertia'),\n",
    "                           ScalarOutcome('reliability')]\n",
    "\n",
    "# override some of the defaults of the model\n",
    "lake_model.constants = [Constant('alpha', 0.41),\n",
    "                            Constant('nsamples', 100),\n",
    "                            Constant('myears', 100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=500, policies=4, uncertainty_sampling=MC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "# print(experiments)\n",
    "maxp_exp = experiments[experiments['policy']%4==0]\n",
    "maxp_exp.drop(columns=['scenario', 'policy', 'model'], inplace=True)\n",
    "# print(maxp_exp)\n",
    "experiments, outcomes = results\n",
    "utility_exp = experiments[experiments['policy']==1]\n",
    "experiments, outcomes = results\n",
    "reliability_exp = experiments[experiments['policy']==2]\n",
    "experiments, outcomes = results\n",
    "inertia_exp = experiments[experiments['policy']==3]\n",
    "\n",
    "# maxp_out = outcomes['max_P'][0:499]\n",
    "selected_scenarios = []\n",
    "\n",
    "from ema_workbench import Scenario\n",
    "\n",
    "for index, row in maxp_exp.iterrows():\n",
    "        selected_scenarios.append(Scenario(str(index), ** row.to_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So i think this stuff below was not supposed to be done in q2, although i am not completely sure. \n",
    "\n",
    "I also think it does work, but it is super slow to run this for 1000 nfe and 500 scenarios. So i might have been a bit impatient when running this. However in my defense, when you wait for 15 minutes and nothing happens it usually means you are having a deadlock, usually. So let me know what you think should happen here, i actually do not know. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] generation 0: 0/1000 nfe\n"
    }
   ],
   "source": [
    "from ema_workbench import (MultiprocessingEvaluator, ema_logging,\n",
    "                           perform_experiments)\n",
    "from ema_workbench.em_framework.evaluators import MC\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from dps_lake_model import lake_model as lakeModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n_scenarios = 500\n",
    "scenarios = sample_uncertainties(lake_model, n_samples=500)\n",
    "nfe = 1000\n",
    "\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    evaluator.robust_optimize(robustnes_maxp_function, scenarios=scenarios, nfe=nfe,\n",
    "                                  epsilons=[0.1], logging_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] generation 0: 0/1000 nfe\n"
    }
   ],
   "source": [
    "from ema_workbench import (MultiprocessingEvaluator, ema_logging,\n",
    "                           perform_experiments)\n",
    "from ema_workbench.em_framework.evaluators import MC\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from dps_lake_model import lake_model as lakeModel\n",
    "\n",
    "n_scenarios = 500\n",
    "# scenarios = sample_uncertainties(lake_model, n_scenarios, sampler=MC)\n",
    "nfe=1000\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    results = evaluator.robust_optimize(robustnes_maxp_function, reference=selected_scenarios, nfe=nfe,epsilons=[0.1], logging_freq=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for candidate solutions\n",
    "Set up the robust optimization problem using the robustness functions you have specified. Assume that you will need 50 scenarios for estimating the robustness. Use $\\epsilon$-progress and hypervolume to track convergence. Solve the optimization problem. As $\\epsilon$ values, you can assume 0.05 for each of the four robustness metrics.\n",
    "\n",
    "*note: this optimization problem is computationally very expensive. Develop and test your code using a sequential evaluator, a low number of function evaluations (e.g., 200), and a low number of scenarios (e.g., 5). Once everything seems to be working replace the sequential evaluator with an multiprocessing or ipyparallel evaluator, and increase the number of nfe and scenarios*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] pool started\n[MainProcess/INFO] generation 0: 0/200 nfe\n[MainProcess/INFO] optimization completed, found 1 solutions\n[MainProcess/INFO] terminating pool\n[MainProcess/INFO] pool started\n[MainProcess/INFO] generation 0: 0/200 nfe\n[MainProcess/INFO] optimization completed, found 1 solutions\n[MainProcess/INFO] terminating pool\n[MainProcess/INFO] pool started\n[MainProcess/INFO] generation 0: 0/200 nfe\n[MainProcess/INFO] optimization completed, found 1 solutions\n[MainProcess/INFO] terminating pool\n[MainProcess/INFO] pool started\n[MainProcess/INFO] generation 0: 0/200 nfe\n[MainProcess/INFO] optimization completed, found 1 solutions\n[MainProcess/INFO] terminating pool\n"
    }
   ],
   "source": [
    "from ema_workbench import (MultiprocessingEvaluator, SequentialEvaluator, ema_logging,\n",
    "                           perform_experiments)\n",
    "from ema_workbench.em_framework.evaluators import MC\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from dps_lake_model import lake_model as lakeModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# robustnes_maxp_function \n",
    "# robustnes_reliability_function \n",
    "# robustnes_inertia_function \n",
    "# robustnes_utility_function \n",
    "# lake_model\n",
    "\n",
    "nfe = 200\n",
    "n_scen = 5\n",
    "scenario = sample_uncertainties(lake_model, n_scen)\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    maxp_res = evaluator.robust_optimize(robustnes_maxp_function, scenarios=scenario, nfe=nfe,epsilons=[0.05])\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    reliability_res = evaluator.robust_optimize(robustnes_reliability_function, scenarios=scenario, nfe=nfe,epsilons=[0.05])\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    utility_res = evaluator.robust_optimize(robustnes_utility_function, scenarios=scenario, nfe=nfe,epsilons=[0.05])\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "with MultiprocessingEvaluator(lake_model) as evaluator:\n",
    "    inertia_res = evaluator.robust_optimize(robustnes_inertia_function, scenarios=scenario, nfe=nfe,epsilons=[0.05])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot your $\\epsilon$-progress to evaluate convergergence, and visualize the trade-offs using parallel coordinate plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this plot tell us about the tradeoffs and conflicting objectives?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate candidate solutions under uncertainty\n",
    "\n",
    "We have used only 50 scenarios for the optimization. Take the results and re-evaluate them over a larger set (assume 1000 scenarios). How different are your results? What does this imply for the assumption of 50 scenarios during robust optimization.\n",
    "\n",
    "*hint: use the to_dict method on a dataframe, next generate Policy objects in a list expression by iterating over the dicts returned by the to_dict method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "If you have time, import your solutions found for MORDM and re-evaluate them over the same set of scnearios as used for re-evaluating the MORO results. Compare the robustness of MORDM and MORO, what do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitc695bbccf217448cbeb1e12ff6afe318"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}