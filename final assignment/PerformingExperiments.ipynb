{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments Performing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, some experiments with different numbers of scenarios and policies will be done. And all the results will be saved for further explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the dike model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teres\\Anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:22: UserWarning: ipyparallel not installed - IpyparalleEvaluator not available\n",
      "  'ipyparallel not installed - IpyparalleEvaluator not available')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Logger EMA (DEBUG)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ema_workbench import ema_logging, MultiprocessingEvaluator\n",
    "from ema_workbench import Model, RealParameter, ScalarOutcome, CategoricalParameter, IntegerParameter, BooleanParameter\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "# from ema_workbench.em_framework.evaluators import MC\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dike_model_function import DikeNetwork\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "\n",
    "#choose problem formulation number, between 0-5\n",
    "#each problem formulation has its own list of outcomes\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(5)\n",
    "# 5 will lead to fully disaggregated outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 0: No policy implemented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Policy\n",
    "\n",
    "policies_0 = [Policy('no policy', **{l.name: 0 for l in dike_model.levers})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 500 scenarios * 1 policies * 1 model(s) = 500 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 50 cases completed\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 150 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 250 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 350 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 450 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] experiments finished\n"
     ]
    }
   ],
   "source": [
    "#running the model through EMA workbench\n",
    "from ema_workbench import (MultiprocessingEvaluator, ema_logging,\n",
    "                           perform_experiments, SequentialEvaluator)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    " \n",
    "with SequentialEvaluator(dike_model) as evaluator:\n",
    "    results_0 = evaluator.perform_experiments(scenarios = 500, policies = policies_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_0, outcomes_0 = results_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results saved successfully to C:\\Users\\teres\\Documents\\EPA1361-Model-based Decison Making\\EPA1361\\final assignment\\500Scenario_NoPolicy.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Save the results\n",
    "from ema_workbench import save_results\n",
    "\n",
    "save_results(results_0, './500Scenario_NoPolicy.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments 1 : 500 scenarios and 50 policies\n",
    "(It's rather time-consuming and I lowered it to 4000 experiments. Need to ask Erika tmr about how many experiments should be enough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 200 scenarios * 20 policies * 1 model(s) = 4000 experiments\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] 2400 cases completed\n",
      "[MainProcess/INFO] 2800 cases completed\n",
      "[MainProcess/INFO] 3200 cases completed\n",
      "[MainProcess/INFO] 3600 cases completed\n",
      "[MainProcess/INFO] 4000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    }
   ],
   "source": [
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results_1 = evaluator.perform_experiments(scenarios = 200, policies = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results saved successfully to C:\\Users\\teres\\Documents\\EPA1361-Model-based Decison Making\\EPA1361\\final assignment\\200Scenario_20Policy.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from ema_workbench import save_results\n",
    "\n",
    "save_results(results_1, './200Scenario_20Policy.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
